{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageOps, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, anno_class_img):\n",
    "        for t in self.transforms:\n",
    "            img, anno_class_img = t(img, anno_class_img)\n",
    "        return img, anno_class_img\n",
    "\n",
    "\n",
    "class Scale(object):\n",
    "    def __init__(self, scale):\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, img, anno_class_img):\n",
    "\n",
    "        width = img.size[0]\n",
    "        height = img.size[1]\n",
    "        scale = np.random.uniform(self.scale[0], self.scale[1])\n",
    "        scaled_w = int(width * scale)\n",
    "        scaled_h = int(height * scale)\n",
    "        img = img.resize((scaled_w, scaled_h), Image.BICUBIC)\n",
    "        anno_class_img = anno_class_img.resize((scaled_w, scaled_h), Image.NEAREST)\n",
    "        if scale > 1.0:\n",
    "            left = scaled_w - width\n",
    "            left = int(np.random.uniform(0, left))\n",
    "            top = scaled_h-height\n",
    "            top = int(np.random.uniform(0, top))\n",
    "            img = img.crop((left, top, left+width, top+height))\n",
    "            anno_class_img = anno_class_img.crop((left, top, left+width, top+height))\n",
    "        else:\n",
    "            p_palette = anno_class_img.copy().getpalette()\n",
    "            img_original = img.copy()\n",
    "            anno_class_img_original = anno_class_img.copy()\n",
    "            pad_width = width-scaled_w\n",
    "            pad_width_left = int(np.random.uniform(0, pad_width))\n",
    "            pad_height = height-scaled_h\n",
    "            pad_height_top = int(np.random.uniform(0, pad_height))\n",
    "            img = Image.new(img.mode, (width, height), (0, 0, 0))\n",
    "            img.paste(img_original, (pad_width_left, pad_height_top))\n",
    "            anno_class_img = Image.new(anno_class_img.mode, (width, height), (0))\n",
    "            anno_class_img.paste(anno_class_img_original,(pad_width_left, pad_height_top))\n",
    "            anno_class_img.putpalette(p_palette)\n",
    "\n",
    "        return img, anno_class_img\n",
    "\n",
    "\n",
    "class RandomRotation(object):\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __call__(self, img, anno_class_img):\n",
    "        rotate_angle = (np.random.uniform(self.angle[0], self.angle[1]))\n",
    "        img = img.rotate(rotate_angle, Image.BILINEAR)\n",
    "        anno_class_img = anno_class_img.rotate(rotate_angle, Image.NEAREST)\n",
    "\n",
    "        return img, anno_class_img\n",
    "\n",
    "\n",
    "class RandomMirror(object):\n",
    "    def __call__(self, img, anno_class_img):\n",
    "        if np.random.randint(2):\n",
    "            img = ImageOps.mirror(img)\n",
    "            anno_class_img = ImageOps.mirror(anno_class_img)\n",
    "        return img, anno_class_img\n",
    "\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __call__(self, img, anno_class_img):\n",
    "        img = img.resize((self.input_size, self.input_size),Image.BICUBIC)\n",
    "        anno_class_img = anno_class_img.resize((self.input_size, self.input_size), Image.NEAREST)\n",
    "\n",
    "        return img, anno_class_img\n",
    "\n",
    "\n",
    "class Normalize_Tensor(object):\n",
    "    def __init__(self, color_mean, color_std):\n",
    "        self.color_mean = color_mean\n",
    "        self.color_std = color_std\n",
    "\n",
    "    def __call__(self, img, anno_class_img):\n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, self.color_mean, self.color_std)\n",
    "        anno_class_img = np.array(anno_class_img)\n",
    "        index = np.where(anno_class_img == 255)\n",
    "        anno_class_img[index] = 0\n",
    "        anno_class_img = torch.from_numpy(anno_class_img)\n",
    "\n",
    "        return img, anno_class_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfec469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    imgpath_template = os.path.join(rootpath, 'JPEGImages', '%s.jpg')\n",
    "    annopath_template = os.path.join(rootpath, 'SegmentationClass', '%s.png')\n",
    "    \n",
    "    train_id_names = os.path.join(rootpath + 'ImageSets/Segmentation/train.txt')\n",
    "    val_id_names = os.path.join(rootpath + 'ImageSets/Segmentation/val.txt')\n",
    "    \n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "    \n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        train_img_list.append(img_path)\n",
    "        train_anno_list.append(anno_path)\n",
    "        \n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    \n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "        \n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform():\n",
    "    def __init__(self, input_size, color_mean, color_std):\n",
    "        self.data_transform = {\n",
    "            'train': Compose([\n",
    "                Scale(scale=[0.5, 1.5]),\n",
    "                RandomRotation(angle=[-10,10]),\n",
    "                RandomMirror(),\n",
    "                Resize(input_size),\n",
    "                Normalize_Tensor(color_mean, color_std),\n",
    "            ]),\n",
    "            'val': Compose([\n",
    "                Resize(input_size),\n",
    "                Normalize_Tensor(color_mean, color_std)\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, phase, img, anno_class_img):\n",
    "        return self.data_transform[phase](img, anno_class_img)\n",
    "    \n",
    "\n",
    "class VOCDataset(data.Dataset):\n",
    "    def __init__(self, img_list, anno_list, phase, transform):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, anno_class_img = self.pull_item(index)\n",
    "        \n",
    "        return img, anno_class_img\n",
    "    \n",
    "    def pull_item(self, index):\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = Image.open(image_file_path)\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_class_img = Image.open(anno_file_path)\n",
    "        img, anno_class_img = self.transform(self.phase, img, anno_class_img)\n",
    "        \n",
    "        return img, anno_class_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14357c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "        \n",
    "        block_config = [3, 4, 6, 3]\n",
    "        img_size = 475\n",
    "        img_size_8 = np.ceil(img_size/8).astype(np.int8)\n",
    "        \n",
    "        # feature block\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "        \n",
    "        # \n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "        \n",
    "        # \n",
    "        self.decode_feature = DecodePSPFeature(height=img_size, width=img_size, n_classes=n_classes)\n",
    "        \n",
    "        # \n",
    "        self.aux = AuxiliaryPSPlayers(in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "        output_aux = self.aux(x)\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "        \n",
    "        return (output, output_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd344dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "        \n",
    "        self.cbnr_1 = conv2DBatchNormRelu(3,64,3,2,1,1,False)\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(64,64,3,1,1,1,False)\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(64,128,3,1,1,1,False)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47da971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "        \n",
    "        self.add_module('block1', bottleNeckPSP(in_channels, mid_channels, out_channels, stride, dilation))\n",
    "        \n",
    "        for i in range(n_blocks-1):\n",
    "            self.add_module(f\"block{i+2}\", bottleNeckIdentifyPSP(out_channels, mid_channels, stride, dilation))\n",
    "            \n",
    "\n",
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "        \n",
    "        return outputs\n",
    "            \n",
    "            \n",
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "        \n",
    "        self.cbr_1 = conv2DBatchNormRelu(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNormRelu(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cb_residual = conv2DBatchNorm(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        \n",
    "        return self.relu(conv+residual)\n",
    "    \n",
    "    \n",
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "        \n",
    "        self.cbr_1 = conv2DBatchNormRelu(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNormRelu(mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv+residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349865e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "        \n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        \n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        \n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        \n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "   \n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8328ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.cbr = conv2DBatchNormRelu(in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(x, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.cbr = conv2DBatchNormRelu(in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(x, size=(self.height, self.width), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f7431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c919f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f03fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbce0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/dotdash/data/'\n",
    "weights_dir = '/home/dotdash/weights/'\n",
    "target_path = os.path.join(data_dir, 'VOCtrainval_11-May-2012.tar')\n",
    "url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)  \n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    urllib.request.urlretrieve(url, target_path)\n",
    "    tar = tarfile.TarFile(target_path)\n",
    "    tar.extractall(data_dir)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = '/home/dotdash/data/VOCdevkit/VOC2012/'\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath=rootpath)\n",
    "print(train_img_list[0])\n",
    "print(train_anno_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fedcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "train_dataset = VOCDataset(\n",
    "    train_img_list, \n",
    "    train_anno_list, \n",
    "    phase='train',\n",
    "    transform=DataTransform(\n",
    "        input_size=475, \n",
    "        color_mean=color_mean,\n",
    "        color_std=color_std\n",
    "    )\n",
    ")\n",
    "val_dataset = VOCDataset(\n",
    "    val_img_list, \n",
    "    val_anno_list, \n",
    "    phase='val',\n",
    "    transform=DataTransform(\n",
    "        input_size=475, \n",
    "        color_mean=color_mean,\n",
    "        color_std=color_std\n",
    "    )\n",
    ")\n",
    "print(val_dataset.__getitem__(0)[0].shape)\n",
    "print(val_dataset.__getitem__(0)[1].shape)\n",
    "print(val_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858eab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "batch_iterator = iter(dataloaders_dict['val'])\n",
    "imges, anno_class_imges = next(batch_iterator)\n",
    "print(imges.size())\n",
    "print(anno_class_imges.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1003c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "outputs = net(dummy_img)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce796d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9bbf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
